{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3150de",
   "metadata": {},
   "source": [
    "<font size=\"6\"> Gradient Descent Attack on Model Parameters <font/>\n",
    "    \n",
    "<font size=\"3\">    Deep neural network (DNN), being able to effectively learn from a training set and provide highly accurate classification results, has become the de-facto technique used in many mission-critical systems. The security of DNN itself is therefore of great concern. In this paper, we investigate the impact of fault injection attacks on DNN, wherein attackers try to misclassify a specified input pattern into an adversarial class by modifying the parameters used in DNN via fault injection. The authors of the paper titled as \"Fault Injection Attack on Deep Neural Network\" proposed the GDA attack which allows an adversary to cause misclassification of certain input samples by tampering as few parameters as possible and with minimal impact on the accracy of the model on the original learning task. In this notebook, we will implement GDA attack on a ReseNet-20 model trained on CIFAR10.<font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a5195",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Importing the libraries <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9f1c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4428c9de",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Loading the Dataset <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09ef459",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36fc1cb",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Attack Parameters <font/>\n",
    "    \n",
    "The goal is to misclassify an image of cat as dog by perturbing minimum number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff3d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_label = 3 ## Class Cat\n",
    "target_label = 5 ## Class Dog\n",
    "idx = random.sample((np.where(np.argmax(y_train,axis=1) == base_label)[0]).tolist(),1)[0]\n",
    "attack_sampled = x_train[idx,::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0302b560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 108x108 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(1.5,1.5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "ax.imshow(attack_sampled)\n",
    "ax.set_title(\"Image to be missclassified\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2653da0",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Loading the Model <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462a1c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/omid/.local/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 16)   448         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 16)   0           ['activation_1[0][0]',           \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32, 32, 16)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 32, 16)   0           ['activation_3[0][0]',           \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 32, 32, 16)   0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 32, 32, 16)   0           ['activation_5[0][0]',           \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 32, 32, 16)   0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 32)   4640        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 32)   9248        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 32)   544         ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 16, 16, 32)   0           ['conv2d_10[0][0]',              \n",
      "                                                                  'batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 32)   0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 32)  128         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 32)  128         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 16, 16, 32)   0           ['activation_9[0][0]',           \n",
      "                                                                  'batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 32)   0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 32)  128         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 32)  128         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 16, 16, 32)   0           ['activation_11[0][0]',          \n",
      "                                                                  'batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 16, 16, 32)   0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 64)     18496       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 64)    256         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 64)     2112        ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 8, 64)    256         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 8, 8, 64)     0           ['conv2d_17[0][0]',              \n",
      "                                                                  'batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 8, 8, 64)     0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 8, 8, 64)    256         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 8, 8, 64)     0           ['activation_15[0][0]',          \n",
      "                                                                  'batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 8, 8, 64)     0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 8, 8, 64)    256         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 8, 8, 64)    256         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 8, 8, 64)     0           ['activation_17[0][0]',          \n",
      "                                                                  'batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 8, 8, 64)     0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 1, 1, 64)    0           ['activation_19[0][0]']          \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 64)           0           ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           650         ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 10)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's test accuracy before GDA Attack :  0.9057\n"
     ]
    }
   ],
   "source": [
    "model_type = 'cifar10'\n",
    "model = load_model('./'+model_type+'.hdf5',compile=False)\n",
    "print(model.summary())\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(), metrics=['accuracy'])\n",
    "test_acc = model.evaluate(x_test,y_test)[1]\n",
    "print(\"model's test accuracy before GDA Attack : \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c562d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_layer_name = 'dense_1'\n",
    "W,_ = model.get_layer(classification_layer_name).trainable_weights\n",
    "layer_parameters = K.flatten(W)\n",
    "original_W,original_B = model.get_layer(classification_layer_name).get_weights()\n",
    "original_W_flattened = K.flatten(original_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4319e",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Defining the GDA Loss <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff1ce9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.1\n",
    "GDA_loss = model.get_layer(classification_layer_name).output[0,target_label]- beta*K.sum(K.abs(layer_parameters-original_W_flattened))\n",
    "\n",
    "get_W_grads = K.function([model.input],K.gradients(GDA_loss,W))\n",
    "get_l1_distance = K.function([model.input],[K.sum(K.abs(layer_parameters-original_W_flattened))])\n",
    "get_target_output = K.function([model.input],[K.mean(model.output[:,target_label])])\n",
    "get_GDA_loss = K.function([model.input],[GDA_loss])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a4291",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Computing Required Modification to the Final Layer <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f70abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 555 ]   total loss :  3.80649  output value :  0.50085  L1 distance :  2.57149\n",
      " Output value :  0.50085  L1 distance :  2.57149\n"
     ]
    }
   ],
   "source": [
    "input_x = attack_sampled.reshape((1,)+attack_sampled.shape)\n",
    "lr = 1e-4\n",
    "epochs = 1000\n",
    "best_loss = -10e+10\n",
    "final_W = None \n",
    "for e in range(epochs):\n",
    "    W_grads = get_W_grads([input_x])[0]\n",
    "    \n",
    "    curr_W,_ = model.get_layer(classification_layer_name).get_weights()\n",
    "    new_W = curr_W+lr*W_grads\n",
    "    \n",
    "    model.get_layer(classification_layer_name).set_weights([new_W,original_B])\n",
    "\n",
    "    output_value = get_target_output([input_x])[0]\n",
    "    l1_distance = get_l1_distance([input_x])[0]\n",
    "    current_loss = get_GDA_loss([input_x])[0]\n",
    "\n",
    "    if best_loss < current_loss :\n",
    "        best_loss = current_loss\n",
    "        final_W,_ = model.get_layer(classification_layer_name).get_weights()\n",
    "\n",
    "    print('[',e,'] ',\" total loss : \", '{:0.5f}'.format(current_loss),\" output value : \", '{:0.5f}'.format(output_value),\" L1 distance : \", '{:0.5f}'.format(l1_distance) , end='\\r')\n",
    "    \n",
    "    if  0.5 < output_value:\n",
    "        break\n",
    "\n",
    "model.get_layer(classification_layer_name).set_weights([final_W,original_B])\n",
    "output_value = get_target_output([input_x])[0]\n",
    "l1_distance = get_l1_distance([input_x])[0]\n",
    "print(\"\\n Output value : \", '{:0.5f}'.format(output_value),\" L1 distance : \", '{:0.5f}'.format(l1_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b678a",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Modification Compression <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3883d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index:  320\n",
      "GDA output value :  0.50  L1 distance :  2.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index:  480\n",
      "GDA output value :  0.50  L1 distance :  2.57\n",
      "Search index:  560\n",
      "GDA output value :  0.50  L1 distance :  2.57\n",
      "Search index:  600\n",
      "GDA output value :  0.46  L1 distance :  2.22\n",
      "Search index:  580\n",
      "GDA output value :  0.50  L1 distance :  2.56\n",
      "Search index:  590\n",
      "GDA output value :  0.49  L1 distance :  2.44\n",
      "Search index:  595\n",
      "GDA output value :  0.48  L1 distance :  2.34\n",
      "Search index:  592\n",
      "GDA output value :  0.49  L1 distance :  2.40\n",
      "Search index:  593\n",
      "GDA output value :  0.48  L1 distance :  2.38\n",
      "Final search index:  593\n"
     ]
    }
   ],
   "source": [
    "def zero_out(to_index):\n",
    "    flattened_diff_W = K.get_value(K.flatten(final_W-original_W))\n",
    "    sorted_indeces = np.argsort(flattened_diff_W)\n",
    "    flattened_diff_W[sorted_indeces[:to_index]] = 0.0\n",
    "    return K.get_value(K.reshape(K.flatten(original_W)+flattened_diff_W,shape=original_W.shape))\n",
    "\n",
    "min_i = 0\n",
    "max_i = original_W.size\n",
    "search_index = 0\n",
    "while True:\n",
    "    search_index = (min_i+max_i)//2\n",
    "    print('Search index: ', search_index)\n",
    "    GDA_W = zero_out(to_index=search_index)\n",
    "    model.get_layer(classification_layer_name).set_weights([GDA_W,original_B])\n",
    "    output_value = get_target_output([input_x])[0]\n",
    "    l1_distance = get_l1_distance([input_x])[0]\n",
    "    print(\"GDA output value : \", '{:0.2f}'.format(output_value),\" L1 distance : \", '{:0.2f}'.format(l1_distance))\n",
    "    if np.argmax(model.predict(input_x),axis=1)[0] == target_label:\n",
    "        min_i = search_index\n",
    "        GDA_W = zero_out(to_index=search_index+1)\n",
    "        model.get_layer(classification_layer_name).set_weights([GDA_W,original_B])\n",
    "        if np.argmax(model.predict(input_x),axis=1)[0] != target_label:\n",
    "            print('Final search index: ', search_index)\n",
    "            break\n",
    "    else:\n",
    "        max_i = search_index\n",
    "\n",
    "\n",
    "GDA_W = zero_out(to_index=search_index)\n",
    "model.get_layer(classification_layer_name).set_weights([GDA_W,original_B])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(), metrics=['accuracy'])\n",
    "model.save('GDA.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78f4fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's test accuracy after :  0.891\n"
     ]
    }
   ],
   "source": [
    "model = load_model('GDA.hdf5',compile=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(), metrics=['accuracy'])\n",
    "assert np.argmax(model.predict(attack_sampled.reshape((1,)+attack_sampled.shape)),axis=1)[0] == target_label\n",
    "test_acc = model.evaluate(x_test,y_test)[1]\n",
    "print(\"model's test accuracy after : \", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
